# Nginx Load Balancer Configuration for 1 Lakh+ Concurrent Users
# This configuration provides enterprise-grade load balancing with:
# - Multiple upstream servers
# - Health checks and failover
# - SSL termination
# - Caching and compression
# - Rate limiting
# - Security headers
# - Real-time monitoring

# Main context
user nginx;
worker_processes auto;  # Auto-detect CPU cores
worker_rlimit_nofile 65535;  # Increase file descriptor limit
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

# Events context - optimized for high concurrency
events {
    worker_connections 4096;  # Connections per worker
    use epoll;  # Efficient event method for Linux
    multi_accept on;  # Accept multiple connections at once
    accept_mutex off;  # Disable accept mutex for better performance
}

# HTTP context
http {
    # Basic settings
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    # Performance optimizations
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    keepalive_requests 1000;
    types_hash_max_size 2048;
    server_tokens off;  # Hide Nginx version
    
    # Buffer sizes - optimized for high load
    client_body_buffer_size 128k;
    client_max_body_size 50m;
    client_header_buffer_size 1k;
    large_client_header_buffers 4 4k;
    output_buffers 1 32k;
    postpone_output 1460;
    
    # Timeouts
    client_body_timeout 12;
    client_header_timeout 12;
    send_timeout 10;
    
    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;
    
    # Logging format
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';
    
    access_log /var/log/nginx/access.log main;
    
    # Rate limiting zones
    limit_req_zone $binary_remote_addr zone=api:10m rate=100r/m;
    limit_req_zone $binary_remote_addr zone=health:10m rate=1000r/m;
    limit_req_zone $binary_remote_addr zone=bulk:10m rate=10r/m;
    limit_req_zone $binary_remote_addr zone=analytics:10m rate=50r/m;
    
    # Connection limiting
    limit_conn_zone $binary_remote_addr zone=perip:10m;
    limit_conn_zone $server_name zone=perserver:10m;
    
    # Upstream servers - Backend instances
    upstream backend_api {
        # Load balancing method
        least_conn;  # Route to server with least active connections
        
        # Backend servers (add more as needed)
        server 127.0.0.1:10000 weight=3 max_fails=3 fail_timeout=30s;
        server 127.0.0.1:10001 weight=3 max_fails=3 fail_timeout=30s;
        server 127.0.0.1:10002 weight=3 max_fails=3 fail_timeout=30s;
        server 127.0.0.1:10003 weight=2 max_fails=3 fail_timeout=30s backup;
        
        # Keepalive connections to upstream
        keepalive 32;
        keepalive_requests 1000;
        keepalive_timeout 60s;
    }
    
    # Upstream for health checks (lighter load)
    upstream backend_health {
        least_conn;
        server 127.0.0.1:10000 weight=1;
        server 127.0.0.1:10001 weight=1;
        server 127.0.0.1:10002 weight=1;
        keepalive 16;
    }
    
    # Cache settings
    proxy_cache_path /var/cache/nginx/api levels=1:2 keys_zone=api_cache:100m 
                     max_size=1g inactive=60m use_temp_path=off;
    
    proxy_cache_path /var/cache/nginx/static levels=1:2 keys_zone=static_cache:50m 
                     max_size=500m inactive=24h use_temp_path=off;
    
    # Map for cache bypass
    map $request_method $no_cache {
        POST 1;
        PUT 1;
        DELETE 1;
        default 0;
    }
    
    # Security headers map
    map $sent_http_content_type $security_headers {
        ~^text/ "nosniff";
        default "";
    }
    
    # Main server block
    server {
        listen 80;
        listen [::]:80;
        server_name localhost eaiser-api.local;
        
        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;
        add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline';" always;
        
        # Connection limits
        limit_conn perip 50;  # Max 50 connections per IP
        limit_conn perserver 5000;  # Max 5000 connections per server
        
        # Health check endpoint (high frequency, minimal processing)
        location /health {
            limit_req zone=health burst=100 nodelay;
            
            proxy_pass http://backend_health;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Minimal timeouts for health checks
            proxy_connect_timeout 5s;
            proxy_send_timeout 5s;
            proxy_read_timeout 5s;
            
            # Cache health check responses briefly
            proxy_cache api_cache;
            proxy_cache_valid 200 10s;
            proxy_cache_key "$scheme$request_method$host$request_uri";
            proxy_cache_bypass $no_cache;
            proxy_no_cache $no_cache;
            
            # Add cache status header
            add_header X-Cache-Status $upstream_cache_status;
        }
        
        # API endpoints with rate limiting
        location /api/issues {
            # Different rate limits based on method
            location ~ ^/api/issues$ {
                limit_req zone=api burst=20 nodelay;
                proxy_pass http://backend_api;
                
                # Proxy settings
                proxy_http_version 1.1;
                proxy_set_header Connection "";
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                
                # Timeouts
                proxy_connect_timeout 10s;
                proxy_send_timeout 30s;
                proxy_read_timeout 30s;
            }
            
            # Bulk operations (stricter limits)
            location /api/issues/bulk {
                limit_req zone=bulk burst=5 nodelay;
                proxy_pass http://backend_api;
                
                # Proxy settings
                proxy_http_version 1.1;
                proxy_set_header Connection "";
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                
                # Longer timeouts for bulk operations
                proxy_connect_timeout 30s;
                proxy_send_timeout 60s;
                proxy_read_timeout 120s;
            }
            
            # Individual issue operations
            location ~ ^/api/issues/[a-zA-Z0-9]+ {
                limit_req zone=api burst=30 nodelay;
                proxy_pass http://backend_api;
                
                # Proxy settings
                proxy_http_version 1.1;
                proxy_set_header Connection "";
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                
                # Standard timeouts
                proxy_connect_timeout 10s;
                proxy_send_timeout 30s;
                proxy_read_timeout 30s;
            }
        }
        
        # Analytics endpoints (moderate rate limiting)
        location /api/analytics {
            limit_req zone=analytics burst=10 nodelay;
            
            proxy_pass http://backend_api;
            
            # Proxy settings
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Cache analytics responses
            proxy_cache api_cache;
            proxy_cache_valid 200 300s;  # 5 minutes
            proxy_cache_key "$scheme$request_method$host$request_uri$args";
            proxy_cache_bypass $no_cache;
            proxy_no_cache $no_cache;
            
            add_header X-Cache-Status $upstream_cache_status;
        }
        
        # General API endpoints
        location /api/ {
            limit_req zone=api burst=50 nodelay;
            
            proxy_pass http://backend_api;
            
            # Proxy settings
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Standard timeouts
            proxy_connect_timeout 10s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
        }
        
        # Static files (if any)
        location /static/ {
            alias /var/www/static/;
            expires 1y;
            add_header Cache-Control "public, immutable";
            
            # Enable caching
            proxy_cache static_cache;
            proxy_cache_valid 200 24h;
        }
        
        # Metrics endpoint for monitoring
        location /nginx-metrics {
            # Restrict access to monitoring systems
            allow 127.0.0.1;
            allow 10.0.0.0/8;
            allow 172.16.0.0/12;
            allow 192.168.0.0/16;
            deny all;
            
            stub_status on;
            access_log off;
        }
        
        # Error pages
        error_page 404 /404.html;
        error_page 500 502 503 504 /50x.html;
        
        location = /50x.html {
            root /usr/share/nginx/html;
        }
        
        location = /404.html {
            root /usr/share/nginx/html;
        }
    }
    
    # HTTPS server (production)
    server {
        listen 443 ssl http2;
        listen [::]:443 ssl http2;
        server_name eaiser-api.local;
        
        # SSL configuration
        ssl_certificate /etc/ssl/certs/eaiser-api.crt;
        ssl_certificate_key /etc/ssl/private/eaiser-api.key;
        
        # SSL optimization
        ssl_session_cache shared:SSL:50m;
        ssl_session_timeout 1d;
        ssl_session_tickets off;
        
        # Modern SSL configuration
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        
        # HSTS
        add_header Strict-Transport-Security "max-age=63072000" always;
        
        # Include same locations as HTTP
        include /etc/nginx/conf.d/api-locations.conf;
    }
    
    # Upstream status monitoring
    server {
        listen 8080;
        server_name localhost;
        
        # Restrict access
        allow 127.0.0.1;
        allow 10.0.0.0/8;
        allow 172.16.0.0/12;
        allow 192.168.0.0/16;
        deny all;
        
        location /upstream-status {
            # This would require nginx-upstream-fair or similar module
            return 200 "Upstream status monitoring";
            add_header Content-Type text/plain;
            access_log off;
        }
        
        location /nginx-status {
            stub_status on;
            access_log off;
        }
    }
}

# Stream context for TCP load balancing (if needed)
stream {
    # Upstream for database connections (if load balancing DB)
    upstream mongodb_cluster {
        server 127.0.0.1:27017 weight=3;
        server 127.0.0.1:27018 weight=2;
        server 127.0.0.1:27019 weight=1 backup;
    }
    
    # Redis cluster load balancing
    upstream redis_cluster {
        server 127.0.0.1:6379 weight=3;
        server 127.0.0.1:6380 weight=3;
        server 127.0.0.1:6381 weight=2;
    }
    
    # MongoDB proxy (if needed)
    server {
        listen 27020;
        proxy_pass mongodb_cluster;
        proxy_timeout 1s;
        proxy_responses 1;
        proxy_connect_timeout 1s;
    }
    
    # Redis proxy (if needed)
    server {
        listen 6390;
        proxy_pass redis_cluster;
        proxy_timeout 1s;
        proxy_responses 1;
        proxy_connect_timeout 1s;
    }
}
